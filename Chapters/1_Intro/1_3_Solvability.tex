\section{Solvability and Nilpotency}

We now begin discussing some nontrivial objects in the theory of Lie algebras. Throughout this section, $L$ will denote an arbitrary Lie algebra.

\subsection{Descending Series of Ideals}

We begin by defining the so-called \textbf{derived series} that consists of repeated derivations, that is, repeated performing of the $'$ operation on a Lie algebra (that is, repeatedly computing the derived subalgebra).

\begin{boxdefinition}[Derived Series]
    The \textbf{derived series} of $L$ is the descending series of ideals
    \begin{align*}
        L = L^{(0)} \supseteq L^{(1)} \supseteq L^{(2)} \supseteq \cdots % \supseteq L^{(n - 1)} \supseteq L^{(n)}
    \end{align*}
    where $L^{(i)} := \brac{L^{(i - 1)}, L^{(i-1)}}$ for $i \geq 1$. % \leq n$.
\end{boxdefinition}

Each $L^{(i)}$ is nothing but the derived subalgebra of $L^{(i - 1)}$.

We have a special term for Lie algebras for which the derived series stabilises at $0$.

\begin{boxdefinition}[Solvability]
    $L$ is said to be \textbf{solvable} if there exists an $n \in \N$ such that $L^{(n)} = 0$.
\end{boxdefinition}

We have already encountered a trivial family of solvable Lie algebras.

\begin{boxexample}
    Every abelian Lie algebra $L$ is solvable. Its derived series is simply
    \begin{align*}
        L = L^{(0)} \supseteq L^{(1)} = \brac{L, L} = 0
    \end{align*}
\end{boxexample}

There is also a less trivial example.

\begin{boxexample}\label{Ch1:Eg:2D_NonAbelian_Lie_Algebra_solvable}
    $\r_2$ (cf. \Cref{Ch1:Eg:2D_NonAbelian_Lie_Algebra}) is solvable. Its derived series is
    \begin{align*}
        \r_2 &= \r_2^{(0)} = \Span{
            \begin{bmatrix}
                1 & 0 \\ 0 & 1
            \end{bmatrix},
            \begin{bmatrix}
                0 & 1 \\ 0 & 0
            \end{bmatrix}
        } \\
        &\supsetneq \r_2^{(1)} = \brac{\r_2, \r_2} = \Span{
            \begin{bmatrix}
                0 & 1 \\ 0 & 0
            \end{bmatrix}
        } \\
        &\supsetneq \r_2^{(2)} = \brac{\r_2^{(1)}, \r_2^{(1)}} = 0
    \end{align*}
    because $\r_2^{(1)}$, being one-dimensional, is abelian.
\end{boxexample}

Given that we understand all Lie algebras of dimension $2$, we can make such seemingly sweeping statements as ``All Lie algebras of dimension $2$ are solvable.''

Next, we define the \textbf{lower central series} of a Lie algebra. This is a series of ideals that is similar to the derived series, but instead of repeatedly taking the derived subalgebra, we repeatedly take the commutator with the parent Lie algebra.

\begin{boxdefinition}[Lower Central Series]
    The \textbf{lower central series} of $L$ is the descending series of ideals
    \begin{align*}
        L = L^{0} \supseteq L^{1} \supseteq L^{2} \supseteq \cdots % \supseteq L^{n - 1} \supseteq L^{n}
    \end{align*}
    where $L^{i} := \brac{L, L^{i-1}}$ for $i \geq 1$. % \leq n$.
\end{boxdefinition}

The use of parentheses when describing the derived series is deliberate: notice that we have dropped the parentheses in the above definition.

\begin{boxconvention}
    Elements of the derived series are denoted $L^{(i)}$, with parenthesised superscript indices, whereas elements of the lower central series are denoted $L^{i}$, with no parentheses around the indices.
\end{boxconvention}

We give a special term to Lie algebras where this process of repeatedly taking the commutator with the parent Lie algebra stabilises at $0$.

\begin{boxdefinition}[Nilpotency]
    $L$ is said to be \textbf{nilpotent} if there exists an $n \in \N$ such that $L^{n} = 0$.
\end{boxdefinition}

The name is not accidental: in nilpotent Lie algebras, all adjoint maps are nilpotent. We will prove this, and even more interesting facts, in due course.

We have already encountered a trivial family of nilpotent Lie algebras.

\begin{boxexample}
    Every abelian Lie algebra $L$ is nilpotent. Its lower central series is simply
    \begin{align*}
        L = L^{0} \supseteq L^{1} = \brac{L, L} = 0
    \end{align*}
\end{boxexample}

There are nontrivial examples as well, but it will be easier to construct them once we develop more machinery.

There is a very important relationship between the derived series and the lower central series.

\begin{boxlemma}\label{Ch1:Lemma:DerivedSeriesContainedInLowerCentralSeries}
    For all $i \in \N$, $L^i \supseteq L^{(i)}$.
\end{boxlemma}
\begin{proof}
    We argue by induction on $i$. The base case is trivial, because $L^0 = L = L^{(0)}$. Now, fix $i \in \N$ and assume that $L^i \supseteq L^{(i)}$. Then,
    \begin{align*}
        L^{i + 1}
        = \brac{L, L^i} &= \brac{L, L^{(i)}} \\
        &= \Span{\setst{\brac{\ell, x}}{x \in L^{(i)}, \ell \in L}} \\
        &\supseteq \Span{\setst{\brac{\ell, x}}{x \in L^{(i)}, \ell \in L^{(i)}}} \\
        &= \brac{L^{(i)}, L^{(i)}} = L^{(i + 1)}
    \end{align*}
    where the inclusion on the third line follows from the fact that $L^{(i)} \subseteq L$. This completes the induction and proves the desired result for all $i \in \N$.
\end{proof}

This gives us a natural relationship between nilpotency and solvability.

\begin{boxcorollary}\label{Ch1:Cor:NilpotentImpliesSolvable}
    If $L$ is nilpotent, then $L$ is solvable.
\end{boxcorollary}
\begin{proof}
    \Cref{Ch1:Lemma:DerivedSeriesContainedInLowerCentralSeries} tells us that for all $n \in \N$, $L^n = 0$ implies $L^{(n)} = 0$. Thus, if such an $n$ exists that makes $L$ nilpotent, the same $n$ would also make $L$ solvable.
\end{proof}

The converse is not true.

\begin{boxcexample}[A Lie algebra that is solvable but not nilpotent]\label{Ch1:CEg:2D_NonAbelian_Lie_Algebra_solvable_not_nilpotent}
    In \Cref{Ch1:Eg:2D_NonAbelian_Lie_Algebra_solvable}, we saw that $\r_2$ is solvable. However, $\r_2$ is not nilpotent: its lower central series stabilises at a nonzero ideal. Explicitly,
    \begin{align*}
        \r_2 &= \r_2^{0} = \Span{
            \begin{bmatrix}
                1 & 0 \\ 0 & 1
            \end{bmatrix},
            \begin{bmatrix}
                0 & 1 \\ 0 & 0
            \end{bmatrix}
        } \\
        &\supsetneq \r_2^{1} = \brac{\r_2, \r_2} = \Span{
            \begin{bmatrix}
                0 & 1 \\ 0 & 0
            \end{bmatrix}
        } \\
        &= \r_2^{2} = \brac{\r_2, \r_2^1} = \Span{
            \brac{
                \begin{bmatrix}
                    1 & 0 \\ 0 & 0
                \end{bmatrix},
                \begin{bmatrix}
                    0 & 1 \\ 0 & 0
                \end{bmatrix}
            }, \brac{
                \begin{bmatrix}
                    0 & 1 \\ 0 & 0
                \end{bmatrix},
                \begin{bmatrix}
                    0 & 1 \\ 0 & 1
                \end{bmatrix}
            }
        } = \Span{
            \begin{bmatrix}
                0 & 1 \\ 0 & 0
            \end{bmatrix}
        } \\
        &= \r_2^{3} = \r_2^{4} = \cdots \\
        &\neq 0
    \end{align*}
\end{boxcexample}

In fact, one can construct several more counterexamples. Once we develop more machinery, we will be able to show, among other things, that every $\t{n}$ is solvable but not nilpotent.

For now, we end this subsection with a fact about the centres of nonzero, nilpotent Lie algebras. The point of the following is that the converse tells us when a nonzero Lie algebra is \textit{not} nilpotent, allowing us to construct counterexamples to the converse of \Cref{Ch1:Cor:NilpotentImpliesSolvable}.

\begin{boxlemma}\label{Ch1:Lemma:NilpotentCentreNonzero}
    If $L$ is nonzero and nilpotent, its centre is nonzero.
\end{boxlemma}
\begin{proof}
    Let $n$ be the largest natural number such that $L^n \neq 0$. That is, let $n \in \N$ be such that
    \begin{align*}
        L = L^0 \supseteq L^1 \supseteq \cdots \supseteq L^n \supsetneq L^{n+1} = 0
    \end{align*}
    We know such an $n$ exists not only because $L$ is nilpotent but also because $L \neq 0$, meaning that the lower central series cannot be trivial (ie, it consists of at least one proper inclusion---namely, that of the zero ideal with a non-zero ideal). By definition, $\brac{L, L^n} = L^{n+1} = 0$. Hence, $L^n = \Zof{L}$. And, as discussed above, $L^n \neq 0$. Therefore, $\Zof{L} \neq 0$, as required.
\end{proof}

We now develop some machinery that allows us to construct solvable and nilpotent Lie \textit{sub}algebras (that would, in particular, imply solvability and nilpotency when we view these Lie subalgebras as Lie algebras in their own right).

\subsection{Ideals, Quotients and Subalgebras}

For a subalgebra to be solvable means exactly what one would imagine.

\begin{boxdefinition}[Solvability of Subalgebras]
    We say a subalgebra of $L$ is \textbf{solvable} if it is solvable as a Lie algebra in its own right.
\end{boxdefinition}

For the remainder of this subsection, fix a Lie algebra $L$ and let $I \nsg L$ and $K \leq L$. It is interesting to explore the relationship between the solvability of $L$, $I$ and $K$.

\begin{boxproposition}[Solvability Conditions]\label{Ch1:Prop:SolvabilityConditions}
    \hfill
    \begin{enumerate}[label = \normalfont\arabic*., noitemsep]
        \item If $L$ is solvable, then so is $\quotient{L}{I}$.
        \item If $L$ is solvable, then so is $K$.
        \item If $I$ and $\quotient{L}{I}$ are solvable, then so is $L$.
    \end{enumerate}
\end{boxproposition}
\begin{proof}
    Let $\phi : L \surj \quotient{L}{I}$ be the quotient homomorphism.
    \begin{enumerate}
        \item Observe that it suffices to show that $\phiof{L^{(i)}} = \phiof{L}^{(i)}$ for all $i \in \N$: if this were true, then the existence of some $n \in \N$ such that $L^{(n)} = 0$ would imply that
        \begin{align*}
            \parenth{\quotient{L}{I}}^{(n)} = \phiof{L}^{(n)} = \phiof{L^{(n)}} = \phiof{0} = 0
        \end{align*}
        making $\quotient{L}{I}$ solvable whenever $L$ is.
        
        We will now prove that $\phiof{L^{(i)}} = \phiof{L}^{(i)}$ by induction on $i$. When $i = 0$, the result is trivial: it is true that $\phiof{L} = \phiof{L}$ by reflexivity. % Lean-like?
        Now, fix $i \in \N$ and assume that $\phiof{L^{(i)}} = \phiof{L}^{(i)}$. Then,
        \begin{align*}
            \phiof{L^{(i + 1)}} = \phiof{\brac{L^{(i)}, L^{(i)}}}
            &= \phiof{\Span{\setst{\brac{x,y}}{x, y \in L^{(i)}}}} \\
            &= \Span{\phiof{\setst{\brac{x,y}}{x, y \in L^{(i)}}}} \\
            &= \Span{\setst{\brac{\phiof{x}, \phiof{y}}}{x, y \in L^{(i)}}} \\
            &= \brac{\phiof{L^{(i)}}, \phiof{L^{(i)}}} \\
            &= \brac{\phiof{L}^{(i)}, \phiof{L}^{(i)}} = \phiof{L}^{(i + 1)}
            % &= \brac{\parenth{\quotient{L}{I}}^{(i)}, \parenth{\quotient{L}{I}}^{(i)}}
            % = \parenth{\quotient{L}{I}}^{(i + 1)}
        \end{align*}
        as required.

        \item It suffices to prove that for all $i \in \N$, $K^{(i)} \subseteq L^{(i)}$: if this were true, then the existence of some $n \in \N$ such that $L^{(n)} = 0$ would imply that $K^{(n)} = 0$, making $K$ solvable whenever $L$ is.
        
        We will now prove that $K^{(i)} \subseteq L^{(i)}$ by induction on $i$. The base case is trivial, because $K^{(0)} = K \subseteq L = L^{(0)}$. Now, fix $i \in \N$ and assume that $K^{(i)} \subseteq L^{(i)}$. Then,
        \begin{align*}
            K^{(i + 1)} = \brac{K^{(i)}, K^{(i)}}
            &= \Span{\setst{\brac{x,y}}{x, y \in K^{(i)}}} \\
            &\subseteq \Span{\setst{\brac{x,y}}{x, y \in L^{(i)}}} \\
            &= \brac{L^{(i)}, L^{(i)}} = L^{(i + 1)}
        \end{align*}
        as required.

        \item Let $m \in \N$ be such that $I^{(m)} = 0$ and let $n \in \N$ be such that $\parenth{\quotient{L}{I}}^{(n)} = 0$. It suffices to prove that for all $i, j \in \N$, $\parenth{L^{(i)}}^{(j)} = L^{(i + j)}$: if this were true, then the fact that
        \begin{align*}
            \phiof{L^{(n)}} = \parenth{\quotient{L}{I}}^{(n)} = 0
        \end{align*}
        would immediately imply that $L^{(n)} \subseteq \pker{\phi} = I$, from which it would follow that $\parenth{L^{(n)}}^{(m)} = 0$, and therefore, that $L^{(n + m)} = 0$, making $L$ solvable whenever $I$ and $\quotient{L}{I}$ are.

        We will now prove that $\parenth{L^{(i)}}^{(j)} = L^{(i + j)}$ by letting $i$ be arbitrary and performing induction on $j$. The base case is trivial, because $\parenth{L^{(i)}}^{(0)} = L^{(i)}$. Now, fix $j \in \N$ and assume that $\parenth{L^{(i)}}^{(j)} = L^{(i + j)}$. Then,
        \begin{align*}
            \parenth{L^{(i)}}^{(j + 1)} = \brac{\parenth{L^{(i)}}^{(j)}, \parenth{L^{(i)}}^{(j)}} = \brac{L^{(i + j)}, L^{(i + j)}} = L^{(i + j + 1)}
        \end{align*}
        as required.
    \end{enumerate}
\end{proof}

We have similar results for nilpotency.

\begin{boxdefinition}[Nilpotency of Subalgebras]
    We say a subalgebra of $L$ is \textbf{nilpotent} if it is solvable as a Lie algebra in its own right.
\end{boxdefinition}

As before, fix a Lie algebra $L$ and let $I \nsg L$ and $K \leq L$. Imposing nilpotency conditions on $L$ allows us to infer the same about $\quotient{L}{I}$ and $K$.

\begin{boxproposition}[Nilpotency Conditions]
    \hfill
    \begin{enumerate}[label = \normalfont\arabic*., noitemsep]
        \item If $L$ is nilpotent, then so is $\quotient{L}{I}$.
        \item If $L$ is nilpotent, then so is $K$.
    \end{enumerate}
\end{boxproposition}

We will not prove these results here, as they are very similar to the corresponding results for solvability. We will, however, mention that the reason why we do not have a nilpotency condition for $L$ when $I$ and $\quotient{L}{I}$ are nilpotent is that it is not, in general, true that $\parenth{L^i}^j = L^{i + j}$ for $i, j \in \N$. The reason why this holds in the derived series is that the derived series is a recursive definition that \textit{does not involve the base case}, meaning that $\parenth{L^{(i)}}^{(j)} = L^{\parenth{i + j}}$---that is, ``taking the derived subalgebra $i$ times and then taking it $j$ times is tantamount to taking it $i + j$ times''---is simply a consequence of ``doing a thing $i$ times and then doing the same thing $j$ times is tantamount to doing it $i + j$ times''. In the case of the lower central series, however, the fact that the recursive definition \textit{involves the base case} makes things problematic, because when we compute the $j$th lower central ideal of $L^i$, \textit{we have a different base case}: we are computing Lie brackets with respect to $L^i$ instead of $L$, meaning that we are ``doing a thing $i$ times and then doing a \textit{different} (if analogous) thing $j$ times''. We see this clearly in the following counterexample.

\begin{boxcexample}[$\r_2$, again]
    $\r_2$ has an ideal $I$ of dimension and co-dimension $1$ spanned by the matrix $E_{12}$ with a $1$ in the $12$ entry and $0$s everywhere else (we have already indirectly shown this in \Cref{Ch1:Eg:2D_NonAbelian_Lie_Algebra_solvable}, so we do not do so explicitly here). Since the dimension and co-dimension of $I$ are $1$, both $I$ and $\quotient{\r_2}{I}$ are abelian, making them nilpotent. However, $\r_2$ is not nilpotent, as we have already shown in \Cref{Ch1:CEg:2D_NonAbelian_Lie_Algebra_solvable_not_nilpotent}. \\

    As one might expect, this is connected to the above discussion. For all $i, j \in \N$, if $i \geq 1$, then $\r_2^{i+j} = I$. However, $\r_2^i = I$ as well, and $I$ is abelian, meaning that $I^j = 0$ if additionally $j \geq 1$. Therefore, for all $i, j \geq 1$, we have $\parenth{\r_2^i}^j = 0 \neq I = \r_2^{i + j}$.
\end{boxcexample}

It turns out that solvability also tells us about the derived subalgebra and codimesions. We begin with a simple observation.

\begin{boxlemma}\label{Ch1:Lemma:AllDerivsOfDerivEqTop}
    $L = L'$ if and only if $\forall i \in \N$, $L^{(i)} = L^{(1)} = L' = L$.
\end{boxlemma}
\begin{proof}
    One direction is trivial, so we do not bother to prove it. To prove that if $L$ equals its derived subalgebra then $L$ equals all subsequent derived subalgebras, we argue by induction on $i$. The base case is trivial, because $L^{(0)} = L$. Now, fix $i \in \N$ and assume that $L^{(i)} = L$. Then,
    \begin{align*}
        L^{(i + 1)} = \brac{L^{(i)}, L^{(i)}} = \brac{L, L} = L'
    \end{align*}
    Furthermore, it is clear that $L^{(1)} = L'$, and, by assumption, $L' = L$. This completes the induction and proves the desired result for all $i \in \N$.
\end{proof}

There is an immediate (and somewhat trivial) consequence.

\begin{boxcorollary}\label{Ch1:Cor:DerivedSubalgLtOfSolvable}
    If $L \neq 0$, then $L$ is solvable if and only if $L' < L$.
\end{boxcorollary}
\begin{proof}
    We know, from \Cref{Ch1:Lemma:AllDerivsOfDerivEqTop}, that $L' = L$ if and only if $L^{(i)} = L$ for all $i \in \N$. In particular, since $L$ is nonzero, none of the $L^{(i)}$ can be zero, which is true if and only if $L$ is not solvable. Therefore, $L$ is solvable if and only if $L' \neq L$, which is equivalent to $L' < L$.
\end{proof}

There is also a less immediate consequence that comes from applying a combination of \Cref{Ch1:Cor:DerivedSubalgLtOfSolvable} and the Correspondence Theorem (\Cref{SP:Thm:Correspondence}) to the ideals of quotient spaces of solvable Lie algebras.

\begin{boxcorollary}\label{Ch1:Cor:ExistsIdealCodim1}
If $L \neq 0$ and $L$ is solvable, there exists an ideal $I \nsg L$ of codimension $1$.
\end{boxcorollary}
\begin{proof}
    Consider the quotient Lie algebra $K := \quotient{L}{L'}$. We know that $0 < K$, because $K = 0$ would imply that $L = L'$, which is impossible because $L$ is solvable, as shown in \Cref{Ch1:Cor:DerivedSubalgLtOfSolvable}. Therefore, $K$ contains a subspace $W$ of dimension $1$. Since $K$ is abelian, \Cref{Ch1:Prop:SubspaceIdealOfAbelian} tells us that $W$ is an ideal of $K$. The Correspondence Theorem (\Cref{SP:Thm:Correspondence}) then tells us that the preimage $V$ of $W$ under the quotient epimorphism is an ideal of $L$ that contains $L'$. Simple arithmetic and dimension results from linear algebra then tell us
    \begin{align*}
        \pdim{V} = \pdim{W} + \pdim{L'} = \parenth{\pdim{L} - \pdim{L'} - 1} + \pdim{L'} = \pdim{L} - 1
    \end{align*}
\end{proof}

% Is the converse true? I wanna say it is... surely if such an I exists then L / I is an ideal of L / L'...

\subsection{The Radical Ideal}

Throughout this subsection, we will assume that $L$ is finite-dimensional.

We begin with a basic result about the sums of ideals.

\begin{boxlemma}\label{Ch1:Lemma:DerivedSeries_sum_contained_sum_derivedSeries}
    Let $I, J \nsg L$. For all $k \in \N$, we have
    \begin{align*}
        \parenth{I + J}^{(k)} \subseteq I^{(k)} + J^{(k)}
    \end{align*}
\end{boxlemma}
\begin{proof}
    We argue by induction on $k$. The base case is trivial, because $(I + J)^{(0)} = I + J = I^{(0)} + J^{(0)}$. Now, fix $k \in \N$ and assume that $(I + J)^{(k)} \subseteq I^{(k)} + J^{(k)}$. Then,
    \begin{align*}
        (I + J)^{(k + 1)} &= \brac{(I + J)^{(k)}, (I + J)^{(k)}} \\
        &\subseteq \brac{I^{(k)} + J^{(k)}, I^{(k)} + J^{(k)}} \\
        &\subseteq \brac{I^{(k)}, I^{(k)}} + \brac{I^{(k)}, J^{(k)}} + \brac{J^{(k)}, I^{(k)}} + \brac{J^{(k)}, J^{(k)}} \\
        &\subseteq I^{(k + 1)} + J^{(k + 1)}
    \end{align*}
    as required.
\end{proof}

\begin{boxlemma}\label{Ch1:Lemma:SumIdealSolvable}
    Let $I, J \nsg L$. If $I$ and $J$ are solvable, then so is $I + J \nsg L$.
\end{boxlemma}
\begin{proof}
    Let $n \in \N$ be such that $I^{(n)} = 0$ and let $m \in \N$ be such that $J^{(m)} = 0$. Since $m + n \geq m, n$ and $I^{(n)} = J^{(m)} = 0$, we know that $I^{(n + m)} = J^{(n + m)} = 0$. Then, applying \Cref{Ch1:Lemma:DerivedSeries_sum_contained_sum_derivedSeries}, we have
    \begin{align*}
        (I + J)^{(n + m)} \subseteq I^{(n + m)} + J^{(n + m)} = 0 + 0 = 0
    \end{align*}
    proving that the derived series of $I + J$ eventually stabilises at $0$. Therefore, $I + J$ is solvable.
    % Apply 2nd iso thm
\end{proof}

\begin{boxcorollary}\label{Ch1:Cor:RadExists}
    There exists a solvable ideal of $L$ that contains all other solvable ideals of $L$.
\end{boxcorollary}
\begin{proof}
    Let $R$ be a solvable ideal of $L$ of maximal dimension.\footnote{When we say maximal dimension, we mean that the dimension of $R$ is the largest possible dimension such that a solvable ideal of that dimension exists. This is well-defined because $L$ is finite-dimensional, and the dimension of any ideal of $L$ is necessarily $\leq \pdim{L}$.} Now, fix any $I \nsg L$. \Cref{Ch1:Lemma:SumIdealSolvable} tells us that $I + R$ is a solvable ideal of $L$. But, since $R$ is of maximal dimension, we know that $\pdim{I + R} \leq \pdim{R}$. Therefore, we must have that $I + R = R$. Then, we must have that $I \subseteq R$, as any $i \in I$ is expressible as $i + 0$, and since $0 \in R$, we have $i = i + 0 \in I + R = R$.
\end{proof}

This solvable ideal has a name.

\begin{boxdefinition}[Radical Ideal]
    The \textbf{radical ideal} of $L$ is the solvable ideal of $L$ that contains all other solvable ideals of $L$, which we know exists from \Cref{Ch1:Cor:RadExists}.
\end{boxdefinition}

We can now define what it means for a Lie algebra to be semi-simple. We will be very interested in this class of Lie algebras going forward.

\begin{boxdefinition}[Semi-Simplicity]\label{Ch1:Def:SemiSimple}
    We say that $L$ is \textbf{semi-simple} if its radical ideal is the $0$ ideal.
\end{boxdefinition}

Our aim for this module will be to classify all semi-simple Lie algebras. We will do this by first classifying all solvable Lie algebras and then using that classification to classify all semi-simple Lie algebras. We will need a \textit{lot} more machinery before we can do this, but we will get there eventually.

We also have a notion of simplicity, which is no different from what we would expect in groups.

\begin{boxdefinition}[Simplicity]
    We say that $L$ is \textbf{simple} if it has no nontrivial ideals.
\end{boxdefinition}

\subsection{Ascending Series of Ideals}

We will end by talking about ascending series of ideals and their corresponding quotients. Throughout this subsection, $L$ will denote an arbitrary Lie algebra.

\begin{boxdefinition}[Ascending Central Series]
    We say that an increasing chain of ideals
    \begin{align*}
        0 \subseteq L_1 \subseteq L_2 \subseteq L_3 \subseteq \cdots
    \end{align*}
    is an \textbf{ascending central series} of $L$ if $L_1 = \Zof{L}$ and for all $i \in \N$, we have
    \begin{enumerate}
        \item $L_i \nsg L$ with quotient map $g_i : L \surj \quotient{L}{L_i}$
        \item $L_{i + 1} = g_i\inv\!\parenth{\Zof{\quotient{L}{L_i}}}$
    \end{enumerate}
\end{boxdefinition}

\begin{boxconvention}
    We will use subscripted $L_i$s to denote elements of the ascending central series, in contrast to superscripts used for the descending central series.
\end{boxconvention}

We now have an equivalent criterion for nilpotency.

\begin{boxproposition}
    $L$ is nilpotent if and only if $L_n = L$ for some $n \in \N$.
\end{boxproposition}
\begin{proof} \hfill
    \begin{description}
        \item[$\parenth{\implies}$]
            One can show by induction on $n$ that if $L^n = 0$, then $L_n = L$. Then, if $\exists n \in \N$ such that $L^n = 0$, ie, if $L$ is nilpotent, then $L_n = 0$ as well.  \sorry % (Same n works for both)

        \item[$\parenth{\impliedby}$] 
            % Use fact that image of centre in quotient map is centre of quotient
            % The idea is to show that $L^{k + 1} = \brac{L, L^k} \subseteq L_{n + k - 1}$ and $\brac{L, L^k} \subseteq \brac{L, L_{n - l}}$. And $L_{n - k}$ is the preimage of $\Zof{\quotient{L}{L_{n - k - 1}}}$
            \sorry
    \end{description}
\end{proof}

We end with another counterexample that shows that solvable Lie algebras need not be nilpotent.

\begin{boxcexample}
    For all $n$, $\t{n}$ is solvable but not nilpotent.
    \begin{proof}[Proof that $\t{n}$ is solvable]
        First, observe that $\brac{\t{n}, \t{n}} = \t{n}' = \u{n}$. By \sorry, we know that $\u{n}$ is nilpotent. Therefore, $\u{n}$ is solvable. Furthermore, $\quotient{\t{n}}{\t{n}'}$ is abelian, making it solvable by \sorry. Therefore, by \Cref{Ch1:Prop:SolvabilityConditions}, $\t{n}$ is solvable.
    \end{proof}

    \begin{proof}[Proof that $\t{n}$ is not nilpotent]
        
    \end{proof}
\end{boxcexample}
